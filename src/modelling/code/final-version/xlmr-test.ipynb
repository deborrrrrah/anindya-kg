{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"xlmr-test.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOi2kjr9mFwf6GSSDkcM1YQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"a436eef0021a403abca179efd7bb9f4b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0171182f56ac4cfeb25340f0ba4f75da","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_aebaa5bd38c94cae83b8b8a864b9d397","IPY_MODEL_310b378aef014876960b5c3daf01bfa6"]}},"0171182f56ac4cfeb25340f0ba4f75da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aebaa5bd38c94cae83b8b8a864b9d397":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c368e5221b14426b8021fed720c09465","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":5069051,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":5069051,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cdd327c48eec44ee97b0368321c1a8cf"}},"310b378aef014876960b5c3daf01bfa6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bb089b8ae1e74cc2b43e65096930e125","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5.07M/5.07M [00:02&lt;00:00, 2.15MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cd6a81e7d2374c9a86ce1a76ae072ef3"}},"c368e5221b14426b8021fed720c09465":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"cdd327c48eec44ee97b0368321c1a8cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bb089b8ae1e74cc2b43e65096930e125":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"cd6a81e7d2374c9a86ce1a76ae072ef3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"5VWnbX-sZLU0","colab_type":"text"},"source":["Most of the code is from [Tutorial from Depends on The Definition](https://www.depends-on-the-definition.com/named-entity-recognition-with-bert/) but modified for this final project task and domain."]},{"cell_type":"markdown","metadata":{"id":"Ob4C6KOI5eWQ","colab_type":"text"},"source":["# Setup and Import Library"]},{"cell_type":"code","metadata":{"id":"1hzSN9Wi5QDs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":120},"executionInfo":{"status":"ok","timestamp":1597412178189,"user_tz":-420,"elapsed":27437,"user":{"displayName":"Deborah Aprilia Josephine","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyhRHl40XtL60mXaDGfeVxG_C2YmtBOdwntGA=s64","userId":"08761981170625811706"}},"outputId":"7e80d1cd-c392-4409-9b4e-aceed7ca3e1d"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y43RurGo5a9u","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597412178194,"user_tz":-420,"elapsed":27415,"user":{"displayName":"Deborah Aprilia Josephine","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyhRHl40XtL60mXaDGfeVxG_C2YmtBOdwntGA=s64","userId":"08761981170625811706"}}},"source":["%notebook inline"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"AZkSrT0f5b7B","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597412178196,"user_tz":-420,"elapsed":27403,"user":{"displayName":"Deborah Aprilia Josephine","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyhRHl40XtL60mXaDGfeVxG_C2YmtBOdwntGA=s64","userId":"08761981170625811706"}}},"source":["ROOT_PATH = '/content/drive/My Drive/Tugas/Tugas Semester 8/Tugas Akhir/13516152 - Deborah Aprilia Josephine/';"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZTJfUcIt5d0a","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":603},"executionInfo":{"status":"ok","timestamp":1597412187445,"user_tz":-420,"elapsed":36612,"user":{"displayName":"Deborah Aprilia Josephine","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyhRHl40XtL60mXaDGfeVxG_C2YmtBOdwntGA=s64","userId":"08761981170625811706"}},"outputId":"e41dbeb2-a980-49e8-e4cd-b86c0071dc85"},"source":["!pip install transformers"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n","\u001b[K     |████████████████████████████████| 778kB 2.8MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Collecting sentencepiece!=0.1.92\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 16.3MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 20.0MB/s \n","\u001b[?25hCollecting tokenizers==0.8.1.rc1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 24.0MB/s \n","\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=4f632a8834f549b1af19a13272e830a4ea7f7dba028825a6ca3420cc9b954c71\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gqiMbRV46ie9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":266},"executionInfo":{"status":"ok","timestamp":1597412195233,"user_tz":-420,"elapsed":44362,"user":{"displayName":"Deborah Aprilia Josephine","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyhRHl40XtL60mXaDGfeVxG_C2YmtBOdwntGA=s64","userId":"08761981170625811706"}},"outputId":"01df0da4-ad92-4b84-f941-cbd5b87629b3"},"source":["!pip install seqeval"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting seqeval\n","  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.18.5)\n","Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval) (2.4.3)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (3.13)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (2.10.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.4.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->Keras>=2.2.4->seqeval) (1.15.0)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=397c01f6f54f00f2c8d18454d98428f58cc844f3142a9779d8ae68b07c5b8ffe\n","  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-0.0.12\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mBDnTl1W6kQ6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597412201480,"user_tz":-420,"elapsed":50573,"user":{"displayName":"Deborah Aprilia Josephine","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyhRHl40XtL60mXaDGfeVxG_C2YmtBOdwntGA=s64","userId":"08761981170625811706"}},"outputId":"cd6a4ec6-0bf9-41a8-c59b-efb58612e91a"},"source":["import pandas as pd \n","import numpy as np\n","import json\n","\n","import torch\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from transformers import BertTokenizer, BertConfig, XLMRobertaTokenizer, XLMRobertaConfig, DistilBertTokenizer, DistilBertConfig\n","\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","\n","import transformers\n","from transformers import AdamW\n","\n","from seqeval.metrics import f1_score, accuracy_score\n","from seqeval.metrics import classification_report\n","\n","transformers.__version__\n","torch.__version__"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'1.6.0+cu101'"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"H4juf63-F-VA","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597412201483,"user_tz":-420,"elapsed":50562,"user":{"displayName":"Deborah Aprilia Josephine","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyhRHl40XtL60mXaDGfeVxG_C2YmtBOdwntGA=s64","userId":"08761981170625811706"}}},"source":["model_type = \"xlmr\"\n","FINE_TUNING_TYPE = \"full\"\n","VERSION = \"final\"\n","SCENARIO = 3\n","EPOCH_CONST = 25\n","BATCH_SIZE = 8\n","WEIGHT_DECAY_RATE = 0.01\n","TRAINING_SIZE = None\n","TESTING_SIZE = None"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"S5dBlVJn9Mgu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":83},"executionInfo":{"status":"ok","timestamp":1597412201485,"user_tz":-420,"elapsed":50527,"user":{"displayName":"Deborah Aprilia Josephine","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyhRHl40XtL60mXaDGfeVxG_C2YmtBOdwntGA=s64","userId":"08761981170625811706"}},"outputId":"ab3ee247-9470-4df6-d466-0d931f4c6f99"},"source":["experiment_information = model_type + \"_v\" + str(VERSION)\n","if FINE_TUNING_TYPE == \"full\" :\n","  experiment_information += \"_full\"\n","elif FINE_TUNING_TYPE == \"partial\" :\n","  experiment_information += \"_partial\"\n","\n","print (\"Info\", experiment_information)\n","\n","MODEL_PATH = ROOT_PATH + \"model/scenario \" + str(SCENARIO) + '/'\n","RESULT_PATH = ROOT_PATH + \"result/scenario \" + str(SCENARIO) + '/'\n","DATASET_PATH = ROOT_PATH + \"dataset/version \" + str(VERSION) + '/'\n","ANALYZE_PATH = ROOT_PATH + \"analyze/version \" + str(VERSION) + '/'\n","MODEL_FILENAME = experiment_information + \".pth\"\n","\n","print (MODEL_PATH)\n","print (RESULT_PATH)\n","print (DATASET_PATH)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Info xlmr_vfinal_full\n","/content/drive/My Drive/Tugas/Tugas Semester 8/Tugas Akhir/13516152 - Deborah Aprilia Josephine/model/scenario 3/\n","/content/drive/My Drive/Tugas/Tugas Semester 8/Tugas Akhir/13516152 - Deborah Aprilia Josephine/result/scenario 3/\n","/content/drive/My Drive/Tugas/Tugas Semester 8/Tugas Akhir/13516152 - Deborah Aprilia Josephine/dataset/version final/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DAHKFfYs6lTH","colab_type":"text"},"source":["# Dataset"]},{"cell_type":"code","metadata":{"id":"KDD6rR5p6nF6","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597412201488,"user_tz":-420,"elapsed":50455,"user":{"displayName":"Deborah Aprilia Josephine","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyhRHl40XtL60mXaDGfeVxG_C2YmtBOdwntGA=s64","userId":"08761981170625811706"}}},"source":["def read_json(filename) :\n","  with open(filename, 'r', encoding=\"utf8\") as f:\n","    obj = json.load(f)\n","  return obj\n","\n","def write_json(obj, filename) :\n","  with open(filename, 'w', encoding=\"utf8\") as outfile:\n","    json.dump(obj, outfile)\n","  print (\"Successfully write JSON obj to\", filename)\n","\n","def write_tsv(obj, filename) :\n","  file = open(filename, \"w\", encoding=\"utf-8\") \n","  for tokens in obj :\n","    for token in tokens :\n","      file.write(token['token'] + \"\\t\" + token['label'] + \"\\n\")\n","    file.write(\"==\\n\\n\")\n","  file.close()\n","  print (\"Successfully write JSON obj to\", filename)\n","\n","def read_tsv(filename) :\n","  file = open(filename, \"r\") \n","  obj = {}\n","  items = []\n","  words = file.read().split(\"==\\n\\n\")\n","  sentences = [[tokens.split(\"\\t\") for tokens in word.split(\"\\n\")] for word in words]\n","  for tokens in sentences :\n","    item = []\n","    for token in tokens :\n","      if len(token) == 2 :\n","        tok_lab = {}\n","        tok_lab['token'] = token[0]\n","        tok_lab['label'] = token[1]\n","        item.append(tok_lab)\n","    if len(item) > 1 :\n","      items.append(item)\n","  obj['tokens_labels'] = items\n","  return obj\n","\n","def write_to_txt(obj, filename, key=None) :\n","  file = open(filename, \"w\", encoding=\"utf-8\") \n","  for items in obj :\n","      texts = []\n","      for item in items :\n","        if key :\n","          texts.append(item[key])\n","        else :\n","          texts.append(item)\n","      file.write(\" \".join(texts) + \"\\n\")\n","  file.close()\n","  print (\"Successfully write JSON obj to\", filename)\n","\n","def read_txt(filename) :\n","  results = open(filename, \"r\").readlines()\n","  return results"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"reuBNz5QWLE_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597412201490,"user_tz":-420,"elapsed":50432,"user":{"displayName":"Deborah Aprilia Josephine","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyhRHl40XtL60mXaDGfeVxG_C2YmtBOdwntGA=s64","userId":"08761981170625811706"}}},"source":["LIMIT_SIZE = 5"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"6RXrMO_H6ueO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1597412201491,"user_tz":-420,"elapsed":50398,"user":{"displayName":"Deborah Aprilia Josephine","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyhRHl40XtL60mXaDGfeVxG_C2YmtBOdwntGA=s64","userId":"08761981170625811706"}},"outputId":"a201f997-eb03-4cdb-b8ca-2330b320f3af"},"source":["tag2idx = {\n","    \"1-B-Merek\" : 1,\n","    \"1-I-Merek\" : 2,\n","    \"2-O\" : 3,\n","    \"3-B-NamaProduk\" : 4,\n","    \"3-I-NamaProduk\" : 5,\n","    \"4-B-Varian\" : 6,\n","    \"4-I-Varian\" : 7,\n","    \"5-B-Ukuran\" : 8,\n","    \"5-I-Ukuran\" : 9,\n","    \"6-B-Penggunaan\" : 10,\n","    \"6-I-Penggunaan\" : 11,\n","    \"7-B-Tekstur\" : 12,\n","    \"7-I-Tekstur\" : 13,\n","    \"PAD\" : 14\n","}\n","\n","tag2idx2= {\n","    \"B-Merek\" : 1,\n","    \"I-Merek\" : 2,\n","    \"O\" : 3,\n","    \"B-NamaProduk\" : 4,\n","    \"I-NamaProduk\" : 5,\n","    \"B-Varian\" : 6,\n","    \"I-Varian\" : 7,\n","    \"B-Ukuran\" : 8,\n","    \"I-Ukuran\" : 9,\n","    \"B-Penggunaan\" : 10,\n","    \"I-Penggunaan\" : 11,\n","    \"B-Tekstur\" : 12,\n","    \"I-Tekstur\" : 13,\n","    \"PAD\" : 14\n","}\n","\n","tag_values = [tag for tag in tag2idx2.keys()]\n","print (tag_values)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["['B-Merek', 'I-Merek', 'O', 'B-NamaProduk', 'I-NamaProduk', 'B-Varian', 'I-Varian', 'B-Ukuran', 'I-Ukuran', 'B-Penggunaan', 'I-Penggunaan', 'B-Tekstur', 'I-Tekstur', 'PAD']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aAz7fg0Vh7vL","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597412233462,"user_tz":-420,"elapsed":82364,"user":{"displayName":"Deborah Aprilia Josephine","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyhRHl40XtL60mXaDGfeVxG_C2YmtBOdwntGA=s64","userId":"08761981170625811706"}}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","torch.cuda.get_device_name(0)\n","model = torch.load(MODEL_PATH + MODEL_FILENAME).cuda()"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hKnsKy0n61jb","colab_type":"text"},"source":["# Testing Setup"]},{"cell_type":"code","metadata":{"id":"qr3xuQ53yDU_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":65,"referenced_widgets":["a436eef0021a403abca179efd7bb9f4b","0171182f56ac4cfeb25340f0ba4f75da","aebaa5bd38c94cae83b8b8a864b9d397","310b378aef014876960b5c3daf01bfa6","c368e5221b14426b8021fed720c09465","cdd327c48eec44ee97b0368321c1a8cf","bb089b8ae1e74cc2b43e65096930e125","cd6a81e7d2374c9a86ce1a76ae072ef3"]},"executionInfo":{"status":"ok","timestamp":1597412236716,"user_tz":-420,"elapsed":85601,"user":{"displayName":"Deborah Aprilia Josephine","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyhRHl40XtL60mXaDGfeVxG_C2YmtBOdwntGA=s64","userId":"08761981170625811706"}},"outputId":"6b9927bb-d42c-45fd-e3fc-8d43f60528ba"},"source":["if \"xlmr\" in MODEL_FILENAME:\n","  MODEL_NAME = \"xlm-roberta-base\"\n","  tokenizer = XLMRobertaTokenizer.from_pretrained(MODEL_NAME, do_lower_case=False)\n","\n","elif \"mbert\" in MODEL_FILENAME:\n","  MODEL_NAME = \"bert-base-multilingual-cased\"\n","  tokenizer = BertTokenizer.from_pretrained(MODEL_NAME, do_lower_case=False)"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a436eef0021a403abca179efd7bb9f4b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=5069051.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Y8EDMQ8I7KwQ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597412236723,"user_tz":-420,"elapsed":85603,"user":{"displayName":"Deborah Aprilia Josephine","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyhRHl40XtL60mXaDGfeVxG_C2YmtBOdwntGA=s64","userId":"08761981170625811706"}}},"source":["def tokenize_and_preserve_labels(sentence, text_labels):\n","  tokenized_sentence = []\n","  labels = []\n","\n","  for word, label in zip(sentence, text_labels):\n","\n","    # Tokenize the word and count # of subwords the word is broken into\n","    tokenized_word = tokenizer.tokenize(word)\n","    n_subwords = len(tokenized_word)\n","\n","    # Add the tokenized word to the final tokenized word list\n","    tokenized_sentence.extend(tokenized_word)\n","\n","    # Add the same label to the new list of labels `n_subwords` times\n","    labels.extend([label] * n_subwords)\n","\n","  return tokenized_sentence, labels"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"d1PH0YHF6n-O","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597412273106,"user_tz":-420,"elapsed":121967,"user":{"displayName":"Deborah Aprilia Josephine","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyhRHl40XtL60mXaDGfeVxG_C2YmtBOdwntGA=s64","userId":"08761981170625811706"}},"outputId":"57ba25e9-4dc2-4eb0-c17e-5aba5d1238e7"},"source":["for j in range (4) :\n","  for i in range(3) :\n","    testing_filename = \"test \" + str(i+1) + \"/\" + str(j+1) + \"-label.txt\"\n","    print (testing_filename)\n","\n","    testing_data = read_tsv(DATASET_PATH + testing_filename)\n","    testing_labels = [[object['label'] for object in objects] for objects in testing_data[\"tokens_labels\"]]\n","    testing_sentences = [[object['token'] for object in objects] for objects in testing_data[\"tokens_labels\"]]\n","\n","    if TESTING_SIZE :\n","      testing_labels = testing_labels[:TESTING_SIZE]\n","      testing_sentences = testing_sentences[:TESTING_SIZE]\n","\n","    print (\"Jumlah label\", str(len(testing_labels)), \" Jumlah kalimat\", str(len(testing_sentences)))\n","\n","    MAX_LEN = max(max([len(testing_sentence) for testing_sentence in testing_sentences]), 312)\n","    print (\"Token length\", MAX_LEN, \" Batch size\", BATCH_SIZE)\n","\n","    testing_tokenized_texts_and_labels = [\n","        tokenize_and_preserve_labels(sent, labs)\n","        for sent, labs in zip(testing_sentences, testing_labels)\n","    ]\n","\n","    testing_tokenized_texts = [token_label_pair[0] for token_label_pair in testing_tokenized_texts_and_labels]\n","    testing_labels = [token_label_pair[1] for token_label_pair in testing_tokenized_texts_and_labels]\n","\n","    testing_input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in testing_tokenized_texts],\n","                              maxlen=MAX_LEN, dtype=\"long\", value=0.0,\n","                              truncating=\"post\", padding=\"post\")\n","\n","    testing_tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in testing_labels],\n","                        maxlen=MAX_LEN, value=tag2idx[\"PAD\"], padding=\"post\",\n","                        dtype=\"long\", truncating=\"post\")\n","\n","    testing_attention_masks = [[float(i != 0.0) for i in ii] for ii in testing_input_ids]\n","\n","    test_inputs = torch.tensor(testing_input_ids)\n","    test_tags = torch.tensor(testing_tags)\n","    test_masks = torch.tensor(testing_attention_masks)\n","\n","    test_data = TensorDataset(test_inputs, test_masks, test_tags)\n","    test_sampler = SequentialSampler(test_data)\n","    test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE)\n","\n","    model.eval()\n","\n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_steps, nb_eval_examples = 0, 0\n","    predictions , true_labels = [], []\n","\n","    for batch in test_dataloader:\n","        batch = tuple(t.to(device) for t in batch)\n","        b_input_ids, b_input_mask, b_labels = batch\n","\n","        with torch.no_grad():\n","            outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n","        \n","        logits = outputs[1].detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        eval_loss += outputs[0].mean().item()\n","        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n","        true_labels.extend(label_ids)\n","\n","    eval_loss = eval_loss / len(test_dataloader)\n","    print(\"Validation loss: {}\".format(eval_loss))\n","\n","    pred_tags = [tag_values[p_i] for p, l in zip(predictions, true_labels)\n","                                for p_i, l_i in zip(p, l) if tag_values[l_i - 1] != \"PAD\"]\n","    valid_tags = [tag_values[l_i] for l in true_labels\n","                                  for l_i in l if tag_values[l_i - 1] != \"PAD\"]\n","\n","    print(\"Validation Accuracy: {}\".format(accuracy_score(valid_tags, pred_tags)))\n","    print(\"Validation F1-Score: {}\".format(f1_score(valid_tags, pred_tags)))\n","    print (classification_report(valid_tags, pred_tags))\n","    print()"],"execution_count":15,"outputs":[{"output_type":"stream","text":["test 1/1-label.txt\n","Jumlah label 54  Jumlah kalimat 54\n","Token length 312  Batch size 8\n","Validation loss: 0.08157739901383008\n","Validation Accuracy: 0.9871433603381472\n","Validation F1-Score: 0.9878188047202132\n","            precision    recall  f1-score   support\n","\n","    Ukuran       0.87      1.00      0.93       263\n","NamaProduk       0.99      0.99      0.99      4141\n","Penggunaan       0.99      0.99      0.99       169\n","    Varian       0.98      0.99      0.99       564\n","     Merek       0.98      1.00      0.99        63\n","   Tekstur       0.85      0.92      0.88        24\n","       PAD       1.00      1.00      1.00         5\n","\n"," micro avg       0.98      0.99      0.99      5229\n"," macro avg       0.98      0.99      0.99      5229\n","\n","\n","test 2/1-label.txt\n","Jumlah label 54  Jumlah kalimat 54\n","Token length 312  Batch size 8\n","Validation loss: 0.07644199045275205\n","Validation Accuracy: 0.9869832893579595\n","Validation F1-Score: 0.9872985781990521\n","            precision    recall  f1-score   support\n","\n","    Ukuran       0.87      1.00      0.93       254\n","NamaProduk       0.99      0.99      0.99      4181\n","Penggunaan       0.99      0.99      0.99       174\n","    Varian       0.98      0.99      0.99       544\n","     Merek       0.97      1.00      0.98        61\n","   Tekstur       0.85      0.94      0.89        31\n","       PAD       0.75      0.60      0.67         5\n","\n"," micro avg       0.98      0.99      0.99      5250\n"," macro avg       0.98      0.99      0.99      5250\n","\n","\n","test 3/1-label.txt\n","Jumlah label 54  Jumlah kalimat 54\n","Token length 312  Batch size 8\n","Validation loss: 0.08589828413096257\n","Validation Accuracy: 0.9862573621274318\n","Validation F1-Score: 0.9871757786134413\n","            precision    recall  f1-score   support\n","\n","    Ukuran       0.87      0.99      0.92       253\n","NamaProduk       0.99      0.99      0.99      4111\n","Penggunaan       1.00      1.00      1.00       172\n","    Varian       0.97      0.99      0.98       535\n","     Merek       0.98      1.00      0.99        65\n","   Tekstur       0.80      1.00      0.89        20\n","       PAD       1.00      1.00      1.00         4\n","\n"," micro avg       0.98      0.99      0.99      5160\n"," macro avg       0.98      0.99      0.99      5160\n","\n","\n","test 1/2-label.txt\n","Jumlah label 54  Jumlah kalimat 54\n","Token length 312  Batch size 8\n","Validation loss: 0.334673747420311\n","Validation Accuracy: 0.9460039334882889\n","Validation F1-Score: 0.9481647520313813\n","            precision    recall  f1-score   support\n","\n","    Ukuran       0.69      0.60      0.64       106\n","NamaProduk       0.98      0.97      0.97      4708\n","Penggunaan       0.86      0.99      0.92        79\n","    Varian       0.64      0.77      0.70       340\n","     Merek       0.98      0.99      0.98        88\n","   Tekstur       0.81      0.94      0.87        18\n","\n"," micro avg       0.95      0.95      0.95      5339\n"," macro avg       0.95      0.95      0.95      5339\n","\n","\n","test 2/2-label.txt\n","Jumlah label 54  Jumlah kalimat 54\n","Token length 312  Batch size 8\n","Validation loss: 0.39876959366457804\n","Validation Accuracy: 0.9424606532408191\n","Validation F1-Score: 0.9456676136363636\n","            precision    recall  f1-score   support\n","\n","    Varian       0.61      0.78      0.69       344\n","NamaProduk       0.98      0.97      0.97      4945\n","     Merek       1.00      1.00      1.00       101\n","Penggunaan       0.83      0.98      0.90        91\n","   Tekstur       0.84      0.94      0.89        17\n","    Ukuran       0.63      0.65      0.64       115\n","\n"," micro avg       0.94      0.95      0.95      5613\n"," macro avg       0.95      0.95      0.95      5613\n","\n","\n","test 3/2-label.txt\n","Jumlah label 54  Jumlah kalimat 54\n","Token length 312  Batch size 8\n","Validation loss: 0.45868338857378277\n","Validation Accuracy: 0.9372590255871013\n","Validation F1-Score: 0.9410681399631676\n","            precision    recall  f1-score   support\n","\n","NamaProduk       0.98      0.96      0.97      4714\n","Penggunaan       0.82      0.99      0.89        81\n","    Varian       0.65      0.80      0.72       371\n","     Merek       0.96      0.97      0.96        98\n","   Tekstur       0.93      1.00      0.97        14\n","    Ukuran       0.64      0.67      0.65       144\n","\n"," micro avg       0.94      0.94      0.94      5422\n"," macro avg       0.95      0.94      0.94      5422\n","\n","\n","test 1/3-label.txt\n","Jumlah label 54  Jumlah kalimat 54\n","Token length 312  Batch size 8\n","Validation loss: 0.1384089413498129\n","Validation Accuracy: 0.9797719749908055\n","Validation F1-Score: 0.9805685842825691\n","            precision    recall  f1-score   support\n","\n","    Ukuran       0.95      0.94      0.94       240\n","NamaProduk       0.99      0.99      0.99      4298\n","    Varian       0.94      0.94      0.94       468\n","Penggunaan       0.85      0.96      0.90        94\n","   Tekstur       0.72      1.00      0.84        26\n","     Merek       0.97      1.00      0.99        99\n","\n"," micro avg       0.98      0.98      0.98      5225\n"," macro avg       0.98      0.98      0.98      5225\n","\n","\n","test 2/3-label.txt\n","Jumlah label 54  Jumlah kalimat 54\n","Token length 322  Batch size 8\n","Validation loss: 0.154114944594247\n","Validation Accuracy: 0.9744947064485082\n","Validation F1-Score: 0.9754098360655737\n","            precision    recall  f1-score   support\n","\n","    Varian       0.93      0.93      0.93       488\n","NamaProduk       0.99      0.98      0.99      4989\n","Penggunaan       0.80      0.87      0.83       105\n","   Tekstur       0.49      0.95      0.65        21\n","    Ukuran       0.92      0.96      0.94       274\n","     Merek       0.99      0.99      0.99       101\n","\n"," micro avg       0.98      0.98      0.98      5978\n"," macro avg       0.98      0.98      0.98      5978\n","\n","\n","test 3/3-label.txt\n","Jumlah label 54  Jumlah kalimat 54\n","Token length 312  Batch size 8\n","Validation loss: 0.22087699068444117\n","Validation Accuracy: 0.968886646485032\n","Validation F1-Score: 0.9695587332222124\n","            precision    recall  f1-score   support\n","\n","    Varian       0.90      0.93      0.91       584\n","NamaProduk       0.99      0.98      0.98      4649\n","    Ukuran       0.87      0.94      0.90       231\n","     Merek       0.96      0.99      0.98       110\n","Penggunaan       0.89      0.96      0.92        96\n","   Tekstur       0.76      1.00      0.86        31\n","\n"," micro avg       0.97      0.97      0.97      5701\n"," macro avg       0.97      0.97      0.97      5701\n","\n","\n","test 1/4-label.txt\n","Jumlah label 54  Jumlah kalimat 54\n","Token length 312  Batch size 8\n","Validation loss: 0.5006065751825061\n","Validation Accuracy: 0.9305932531989143\n","Validation F1-Score: 0.933169331693317\n","            precision    recall  f1-score   support\n","\n","     Merek       0.95      0.94      0.95       105\n","NamaProduk       0.97      0.96      0.96      4093\n","    Varian       0.71      0.72      0.71       411\n","    Ukuran       0.77      0.85      0.81       170\n","Penggunaan       0.89      0.99      0.94        67\n","   Tekstur       0.67      0.81      0.73        27\n","       PAD       0.00      0.00      0.00         1\n","\n"," micro avg       0.93      0.93      0.93      4874\n"," macro avg       0.93      0.93      0.93      4874\n","\n","\n","test 2/4-label.txt\n","Jumlah label 54  Jumlah kalimat 54\n","Token length 312  Batch size 8\n","Validation loss: 0.4179448293788092\n","Validation Accuracy: 0.9413063477460901\n","Validation F1-Score: 0.944026570284263\n","            precision    recall  f1-score   support\n","\n","    Ukuran       0.69      0.68      0.69       155\n","NamaProduk       0.96      0.97      0.97      4302\n","    Varian       0.80      0.78      0.79       444\n","   Tekstur       0.67      0.78      0.72        18\n","     Merek       0.96      0.97      0.97       106\n","Penggunaan       0.92      0.99      0.95        77\n","\n"," micro avg       0.94      0.95      0.94      5102\n"," macro avg       0.94      0.95      0.94      5102\n","\n","\n","test 3/4-label.txt\n","Jumlah label 54  Jumlah kalimat 54\n","Token length 312  Batch size 8\n","Validation loss: 0.36516787324632916\n","Validation Accuracy: 0.9420111042566317\n","Validation F1-Score: 0.9417127971344839\n","            precision    recall  f1-score   support\n","\n","NamaProduk       0.97      0.97      0.97      3922\n","     Merek       0.97      0.95      0.96        87\n","    Varian       0.72      0.75      0.73       400\n","Penggunaan       0.93      0.98      0.95        51\n","    Ukuran       0.70      0.68      0.69       107\n","   Tekstur       0.85      0.65      0.73        17\n","       PAD       0.00      0.00      0.00         2\n","\n"," micro avg       0.94      0.95      0.94      4586\n"," macro avg       0.94      0.95      0.94      4586\n","\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mJPoLwnx7omc","colab_type":"text"},"source":["# Analyze"]},{"cell_type":"code","metadata":{"id":"m9nAWsB6jq33","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597412273109,"user_tz":-420,"elapsed":121964,"user":{"displayName":"Deborah Aprilia Josephine","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyhRHl40XtL60mXaDGfeVxG_C2YmtBOdwntGA=s64","userId":"08761981170625811706"}}},"source":["tag_values = [\"1-B-Merek\", \"1-I-Merek\", \"2-O\", \"3-B-NamaProduk\", \"3-I-NamaProduk\", \"4-B-Varian\", \"4-I-Varian\", \"5-B-Ukuran\", \"5-I-Ukuran\", \"6-B-Penggunaan\", \"6-I-Penggunaan\", \"7-B-Tekstur\", \"7-I-Tekstur\", \"PAD\"]"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"PoeiU5U9Dg3U","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597412273111,"user_tz":-420,"elapsed":121962,"user":{"displayName":"Deborah Aprilia Josephine","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyhRHl40XtL60mXaDGfeVxG_C2YmtBOdwntGA=s64","userId":"08761981170625811706"}}},"source":["def predict_text(text) :\n","  model.eval()\n","  result = []\n","  tokenized_sentence = tokenizer.encode(text)\n","  if (len(tokenized_sentence) > 512) :\n","    return None\n","  input_ids = torch.tensor([tokenized_sentence]).cuda()\n","  with torch.no_grad():\n","    output = model(input_ids)\n","  label_indices = np.argmax(output[0].to(\"cpu\").numpy(), axis=2)\n","\n","  # Join Split Token\n","  tokens = tokenizer.convert_ids_to_tokens(input_ids.to(\"cpu\").numpy()[0])\n","  new_tokens, new_labels = [], []\n","  \n","  # Initialize Variables for XLM-R Join Token\n","  result_token = \"\"\n","  result_label = None\n","  \n","  for token, label_idx in zip(tokens, label_indices[0]):\n","    if \"xlmr\" in model_type :\n","      if token.startswith(\"▁\"):\n","        if result_token != \"\" :\n","          new_labels.append(result_label)\n","          new_tokens.append(result_token)\n","        result_token = token[1:]\n","        result_label = tag_values[label_idx -1]\n","      else:\n","        result_token += token\n","    elif \"bert\" in model_type :\n","      if token.startswith(\"##\"):\n","        new_tokens[-1] = new_tokens[-1] + token[2:]\n","      else:\n","        new_labels.append(tag_values[label_idx - 1])\n","        new_tokens.append(token)\n","  \n","  # Append last token from xlmr and remove \"</s>\" from the token\n","  if \"xlmr\" in model_type :\n","    new_labels.append(result_label)\n","    new_tokens.append(result_token.rstrip(\"</s>\"))\n","  for token, label in zip(new_tokens, new_labels):\n","    elmt = {}\n","    elmt[\"token\"] = token\n","    elmt[\"label\"] = label\n","    result.append(elmt)\n","  # Remove [CLS] for mbert and distilbert\n","  del result[0]\n","\n","  # Remove [SEP] for mbert and distilbert\n","  if \"bert\" in model_type : \n","    del result[-1]\n","  return result\n","\n","def predict(texts) :\n","  results = {}\n","  tokens_labels = []\n","  count = 0\n","  for idx, text in enumerate(texts) :\n","    if text != \"\" :\n","      result = self.predict_text(text)\n","      if result != None :\n","        tokens_labels.append(self.predict_text(text))\n","      else :\n","        count += 1\n","  results[\"tokens_labels\"] = tokens_labels\n","  print (\"Skipped text\", count)\n","  return results"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"LkJTQo3Tj0Cv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":216},"executionInfo":{"status":"ok","timestamp":1597412309567,"user_tz":-420,"elapsed":158399,"user":{"displayName":"Deborah Aprilia Josephine","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyhRHl40XtL60mXaDGfeVxG_C2YmtBOdwntGA=s64","userId":"08761981170625811706"}},"outputId":"bf65e129-0526-457a-f6f2-8a6d41c6e36f"},"source":["for test_id in range(3) :\n","  for test_type in range(4) :\n","    analyze_filename = ANALYZE_PATH + \"test \" + str(test_id+1) + \"/\" + model_type + \"_\" + str(test_type+1) + \".txt\" \n","    texts_labels = read_tsv(DATASET_PATH + \"test \" + str(test_id+1) + \"/\" + str(test_type+1) + \"-label.txt\")\n","\n","    file = open(analyze_filename, \"w\", encoding=\"utf-8\") \n","    for idx in range(len(texts_labels[\"tokens_labels\"])) :\n","      texts = []\n","      for token in texts_labels[\"tokens_labels\"][idx] :\n","        texts.append(token[\"token\"])\n","      predicts = predict_text(\" \".join(texts))\n","\n","      if predicts :\n","        for i in range(len(predicts)) :\n","          output = predicts[i][\"token\"] + \"\\t\" + predicts[i][\"label\"]\n","          if \"xlmr\" in model_type :\n","            output += \"\\t\" + texts_labels[\"tokens_labels\"][idx][i][\"label\"] \n","            if texts_labels[\"tokens_labels\"][idx][i][\"label\"] != predicts[i][\"label\"] :\n","              output += \"\\t\" + \"FLAGGED\"\n","          output += \"\\n\"\n","          file.write(output)\n","        file.write(\"==\\n\\n\")\n","    file.close()\n","    print (\"Successfully write JSON obj to\", analyze_filename)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Successfully write JSON obj to /content/drive/My Drive/Tugas/Tugas Semester 8/Tugas Akhir/13516152 - Deborah Aprilia Josephine/analyze/version final/test 1/xlmr_1.txt\n","Successfully write JSON obj to /content/drive/My Drive/Tugas/Tugas Semester 8/Tugas Akhir/13516152 - Deborah Aprilia Josephine/analyze/version final/test 1/xlmr_2.txt\n","Successfully write JSON obj to /content/drive/My Drive/Tugas/Tugas Semester 8/Tugas Akhir/13516152 - Deborah Aprilia Josephine/analyze/version final/test 1/xlmr_3.txt\n","Successfully write JSON obj to /content/drive/My Drive/Tugas/Tugas Semester 8/Tugas Akhir/13516152 - Deborah Aprilia Josephine/analyze/version final/test 1/xlmr_4.txt\n","Successfully write JSON obj to /content/drive/My Drive/Tugas/Tugas Semester 8/Tugas Akhir/13516152 - Deborah Aprilia Josephine/analyze/version final/test 2/xlmr_1.txt\n","Successfully write JSON obj to /content/drive/My Drive/Tugas/Tugas Semester 8/Tugas Akhir/13516152 - Deborah Aprilia Josephine/analyze/version final/test 2/xlmr_2.txt\n","Successfully write JSON obj to /content/drive/My Drive/Tugas/Tugas Semester 8/Tugas Akhir/13516152 - Deborah Aprilia Josephine/analyze/version final/test 2/xlmr_3.txt\n","Successfully write JSON obj to /content/drive/My Drive/Tugas/Tugas Semester 8/Tugas Akhir/13516152 - Deborah Aprilia Josephine/analyze/version final/test 2/xlmr_4.txt\n","Successfully write JSON obj to /content/drive/My Drive/Tugas/Tugas Semester 8/Tugas Akhir/13516152 - Deborah Aprilia Josephine/analyze/version final/test 3/xlmr_1.txt\n","Successfully write JSON obj to /content/drive/My Drive/Tugas/Tugas Semester 8/Tugas Akhir/13516152 - Deborah Aprilia Josephine/analyze/version final/test 3/xlmr_2.txt\n","Successfully write JSON obj to /content/drive/My Drive/Tugas/Tugas Semester 8/Tugas Akhir/13516152 - Deborah Aprilia Josephine/analyze/version final/test 3/xlmr_3.txt\n","Successfully write JSON obj to /content/drive/My Drive/Tugas/Tugas Semester 8/Tugas Akhir/13516152 - Deborah Aprilia Josephine/analyze/version final/test 3/xlmr_4.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ArZRrEbfwQQT","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}